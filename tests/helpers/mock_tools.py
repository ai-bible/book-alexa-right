"""
Mock Tools for Agent Testing

Provides mock implementations of agents using @tool decorator for in-process testing.
"""

from pathlib import Path
import json
from typing import Dict, Any


def create_mock_tools(fixtures_dir: Path = None):
    """
    Create mock tools for testing.

    Returns dictionary of mock tool functions that can be used with
    claude_agent_sdk.tools.create_sdk_mcp_server().

    Args:
        fixtures_dir: Path to fixtures directory (default: tests/fixtures/)

    Returns:
        Dict of tool name to tool function
    """
    if fixtures_dir is None:
        fixtures_dir = Path("tests/fixtures")

    # Try to import claude_agent_sdk tool decorator
    try:
        from claude_agent_sdk import tool
    except ImportError:
        # Fallback mock decorator for testing without SDK
        def tool(name, description, schema):
            def decorator(func):
                func._tool_name = name
                func._tool_description = description
                func._tool_schema = schema
                return func
            return decorator

    @tool("validate_blueprint", "Mock blueprint validator", {
        "blueprint_path": str
    })
    async def mock_blueprint_validator(args: Dict[str, Any]) -> Dict[str, Any]:
        """
        Return fixture-based validation result.

        Args:
            args: {"blueprint_path": str}

        Returns:
            MCP tool response with validation result
        """
        # Determine pass/fail based on fixture
        if "fail" in args.get("blueprint_path", "").lower():
            fixture = fixtures_dir / "agent_responses" / "blueprint-validator-fail.json"
        else:
            fixture = fixtures_dir / "agent_responses" / "blueprint-validator-pass.json"

        if fixture.exists():
            result = json.loads(fixture.read_text())
        else:
            # Fallback result
            result = {
                "status": "PASS",
                "blueprint_path": args.get("blueprint_path"),
                "constraints": {},
                "validation_checks": {},
                "issues": [],
                "warnings": []
            }

        return {
            "content": [{
                "type": "text",
                "text": json.dumps(result, indent=2)
            }]
        }

    @tool("create_verification_plan", "Mock verification plan generator", {
        "blueprint_path": str,
        "constraints": dict
    })
    async def mock_verification_planner(args: Dict[str, Any]) -> Dict[str, Any]:
        """
        Return mock verification plan.

        Args:
            args: {"blueprint_path": str, "constraints": dict}

        Returns:
            MCP tool response with verification plan
        """
        plan = f"""# Verification Plan for {args.get('blueprint_path', 'Unknown')}

## Constraints to Verify

1. **Location**: Verify scene takes place in required location
2. **Characters**: Verify present/absent character constraints
3. **Tone**: Verify tone matches blueprint requirements
4. **Word Count**: Verify {args.get('constraints', {}).get('word_count', {}).get('min', 800)}-{args.get('constraints', {}).get('word_count', {}).get('max', 1200)} words

## Validation Steps

1. Blueprint compliance check
2. World consistency validation
3. Character authenticity verification
4. Temporal logic validation
5. Prose quality assessment
6. Dialogue validation
7. Technical accuracy check

## Expected Outcome

All validators should return PASS status with aggregated score >0.70.
"""
        return {
            "content": [{
                "type": "text",
                "text": plan
            }]
        }

    @tool("generate_prose", "Mock prose writer", {
        "blueprint_path": str,
        "constraints": dict,
        "attempt": int
    })
    async def mock_prose_writer(args: Dict[str, Any]) -> Dict[str, Any]:
        """
        Return fixture-based prose.

        Args:
            args: {"blueprint_path": str, "constraints": dict, "attempt": int}

        Returns:
            MCP tool response with generated prose
        """
        attempt = args.get("attempt", 1)

        # Simulate failure on first attempt if requested
        if "fail_once" in args.get("blueprint_path", "") and attempt == 1:
            prose = "# INVALID PROSE - CONSTRAINT VIOLATION\n\nThis prose violates constraints."
        else:
            fixture = fixtures_dir / "agent_responses" / "prose-writer-success.md"
            if fixture.exists():
                prose = fixture.read_text()
            else:
                # Fallback prose
                prose = """# Test Scene

This is a test scene generated by mock prose writer.

The scene contains minimal content for testing purposes.
"""

        return {
            "content": [{
                "type": "text",
                "text": prose
            }]
        }

    @tool("check_compliance_fast", "Mock fast compliance checker", {
        "draft_path": str,
        "constraints": dict
    })
    async def mock_fast_compliance_checker(args: Dict[str, Any]) -> Dict[str, Any]:
        """
        Return mock fast compliance check result.

        Args:
            args: {"draft_path": str, "constraints": dict}

        Returns:
            MCP tool response with compliance result
        """
        # Determine pass/fail based on draft path
        if "invalid" in args.get("draft_path", "").lower():
            result = {
                "status": "FAIL",
                "violations": [
                    {
                        "type": "location_violation",
                        "severity": "CRITICAL",
                        "message": "Scene location does not match blueprint"
                    }
                ],
                "duration_seconds": 15
            }
        else:
            result = {
                "status": "PASS",
                "violations": [],
                "duration_seconds": 12
            }

        return {
            "content": [{
                "type": "text",
                "text": json.dumps(result, indent=2)
            }]
        }

    @tool("validate_full", "Mock full validation aggregator", {
        "draft_path": str,
        "blueprint_path": str,
        "constraints": dict
    })
    async def mock_validation_aggregator(args: Dict[str, Any]) -> Dict[str, Any]:
        """
        Return fixture-based full validation result.

        Args:
            args: {"draft_path": str, "blueprint_path": str, "constraints": dict}

        Returns:
            MCP tool response with validation report
        """
        # Determine pass/fail
        if "fail" in args.get("draft_path", "").lower():
            fixture = fixtures_dir / "agent_responses" / "validators-fail.json"
        else:
            fixture = fixtures_dir / "agent_responses" / "validators-pass.json"

        if fixture.exists():
            result = json.loads(fixture.read_text())
        else:
            # Fallback result
            result = {
                "overall_status": "PASS",
                "validators_results": {},
                "aggregated_score": 0.90,
                "word_count": 487,
                "decision": "APPROVED_FOR_PUBLICATION"
            }

        return {
            "content": [{
                "type": "text",
                "text": json.dumps(result, indent=2)
            }]
        }

    # Return dict of all mock tools
    return {
        "validate_blueprint": mock_blueprint_validator,
        "create_verification_plan": mock_verification_planner,
        "generate_prose": mock_prose_writer,
        "check_compliance_fast": mock_fast_compliance_checker,
        "validate_full": mock_validation_aggregator
    }


def create_mock_tool_list(fixtures_dir: Path = None) -> list:
    """
    Create list of mock tool functions for SDK.

    Args:
        fixtures_dir: Path to fixtures directory

    Returns:
        List of tool functions
    """
    tools_dict = create_mock_tools(fixtures_dir)
    return list(tools_dict.values())


# Standalone mock tool functions for selective testing

async def mock_blueprint_validator_always_pass(args: Dict[str, Any]) -> Dict[str, Any]:
    """Always pass blueprint validation."""
    return {
        "content": [{
            "type": "text",
            "text": json.dumps({
                "status": "PASS",
                "constraints": {},
                "issues": []
            })
        }]
    }


async def mock_blueprint_validator_always_fail(args: Dict[str, Any]) -> Dict[str, Any]:
    """Always fail blueprint validation."""
    return {
        "content": [{
            "type": "text",
            "text": json.dumps({
                "status": "FAIL",
                "constraints": None,
                "issues": [
                    {
                        "severity": "CRITICAL",
                        "type": "missing_constraints",
                        "message": "Blueprint is incomplete"
                    }
                ]
            })
        }]
    }


async def mock_prose_writer_always_succeed(args: Dict[str, Any]) -> Dict[str, Any]:
    """Always generate valid prose."""
    return {
        "content": [{
            "type": "text",
            "text": "# Valid Test Prose\n\nThis is valid prose that passes all constraints."
        }]
    }


async def mock_prose_writer_fail_once_then_succeed(args: Dict[str, Any]) -> Dict[str, Any]:
    """
    Fail on first attempt, succeed on subsequent attempts.

    Uses global counter to track attempts.
    """
    if not hasattr(mock_prose_writer_fail_once_then_succeed, "_attempt"):
        mock_prose_writer_fail_once_then_succeed._attempt = 0

    mock_prose_writer_fail_once_then_succeed._attempt += 1

    if mock_prose_writer_fail_once_then_succeed._attempt == 1:
        return {
            "content": [{
                "type": "text",
                "text": "# INVALID PROSE\n\nConstraint violations present."
            }]
        }
    else:
        return {
            "content": [{
                "type": "text",
                "text": "# Valid Prose\n\nAll constraints satisfied."
            }]
        }


async def mock_validators_always_pass(args: Dict[str, Any]) -> Dict[str, Any]:
    """Always pass full validation."""
    return {
        "content": [{
            "type": "text",
            "text": json.dumps({
                "overall_status": "PASS",
                "aggregated_score": 0.95,
                "decision": "APPROVED_FOR_PUBLICATION"
            })
        }]
    }


async def mock_validators_always_fail(args: Dict[str, Any]) -> Dict[str, Any]:
    """Always fail full validation."""
    return {
        "content": [{
            "type": "text",
            "text": json.dumps({
                "overall_status": "FAIL",
                "aggregated_score": 0.45,
                "critical_issues_count": 3,
                "decision": "REJECTED_RETRY_REQUIRED"
            })
        }]
    }
